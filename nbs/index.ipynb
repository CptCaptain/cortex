{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from cortex.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cortex\n",
    "\n",
    "> Researching fast and accurate Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Deploy to GitHub Pages](https://github.com/CptCaptain/cortex/actions/workflows/deploy.yaml/badge.svg)](https://github.com/CptCaptain/cortex/actions/workflows/deploy.yaml)\n",
    "[![CI](https://github.com/CptCaptain/cortex/actions/workflows/test.yaml/badge.svg)](https://github.com/CptCaptain/cortex/actions/workflows/test.yaml)\n",
    "\n",
    "This file will become your README and also the index of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install cortex\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point, this will contain (or link to) a gradio demo page, where the different models can be interactively tested in various settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not yet, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this, you might need to tunnel some ports over ssh.  \n",
    "ssh -L8888:localhost:8888 $GPU-SERVER   \n",
    "ssh -L7860:localhost:7860 $GPU-SERVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the demos on new systems, some preparation is currently required.\n",
    "This includes cloning the necessary repositories into the `model_repos` folder, as well as creating a conda env for each repository.\n",
    "A list of the repositries, as well as more detailed instructions for their setup will be provided [TODO]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the variety of models used in this project, not all of them use compatible environments. \n",
    "This necessitates that we switch our enviroments to correspond with the demo we want to use.\n",
    "This might at some point happen automatically, but for now, we have to first expose our conda envs to jupyter and then choose the right kernel before executing the demo.\n",
    "[General instructions on how to do this can be found here](https://jeremyfromearth.medium.com/multiple-python-kernels-for-jupyter-lab-with-conda-c67e50de3aa3)\n",
    "More specific instructions will follow, once the process is more final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, in the yolov7 conda env, run\n",
    "```\n",
    "conda install ipykernel\n",
    "python -m ipykernel install --user --name 'yolov7' --display-name=\"YoloV7\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For setting up the MMDetection environment, installing mmcv-full via MIM is recommended, as this will automatically install a (CUDA-) compatible version. Doing so manually can result in issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using conda, calling mim via `python -m mim install ...` might be advisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
